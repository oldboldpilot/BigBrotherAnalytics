#!/usr/bin/env python3
"""
BigBrotherAnalytics: Alert System Test Script
Generate test alerts to validate the entire alert system

Author: Olumuyiwa Oluwasanmi
Date: 2025-11-10
Phase 4, Week 3: Custom Alerts System
"""

import sys
import time
import json
from pathlib import Path
from datetime import datetime

# Add project root to path
BASE_DIR = Path(__file__).parent.parent.parent
sys.path.insert(0, str(BASE_DIR))

import duckdb


def test_alert_database_schema():
    """Test 1: Verify alerts database schema is created."""
    print("\n" + "=" * 70)
    print("TEST 1: Database Schema Verification")
    print("=" * 70)

    try:
        db_path = BASE_DIR / 'data' / 'bigbrother.duckdb'
        conn = duckdb.connect(str(db_path), read_only=False)

        # Check if alerts table exists
        tables = conn.execute("SHOW TABLES").fetchall()
        table_names = [t[0] for t in tables]

        if 'alerts' not in table_names:
            print("‚ùå FAILED: Alerts table not found")
            print("   Run: uv run python scripts/monitoring/setup_alerts_database.py")
            return False

        print("‚úÖ PASSED: Alerts table exists")

        # Check table structure
        columns = conn.execute("DESCRIBE alerts").fetchall()
        column_names = [c[0] for c in columns]

        required_columns = ['id', 'alert_type', 'alert_subtype', 'severity',
                           'message', 'context', 'timestamp', 'sent']

        missing = [col for col in required_columns if col not in column_names]
        if missing:
            print(f"‚ùå FAILED: Missing columns: {missing}")
            return False

        print(f"‚úÖ PASSED: All required columns present ({len(column_names)} total)")

        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå FAILED: {e}")
        return False


def test_insert_sample_alerts():
    """Test 2: Insert sample alerts of all types."""
    print("\n" + "=" * 70)
    print("TEST 2: Insert Sample Alerts")
    print("=" * 70)

    try:
        db_path = BASE_DIR / 'data' / 'bigbrother.duckdb'
        conn = duckdb.connect(str(db_path), read_only=False)

        # Sample alerts for each type and severity
        sample_alerts = [
            # Trading alerts
            {
                'type': 'trading',
                'subtype': 'position_opened',
                'severity': 'INFO',
                'message': 'Position opened: AAPL (size: $1,500.00)',
                'context': json.dumps({'symbol': 'AAPL', 'size': 1500.0})
            },
            {
                'type': 'trading',
                'subtype': 'stop_loss_triggered',
                'severity': 'ERROR',
                'message': 'Stop-loss triggered for TSLA - Loss: $150.00',
                'context': json.dumps({'symbol': 'TSLA', 'loss': 150.0})
            },
            {
                'type': 'trading',
                'subtype': 'pnl_threshold',
                'severity': 'WARNING',
                'message': 'P&L threshold reached: $250.00 on portfolio',
                'context': json.dumps({'pnl': 250.0, 'symbol': 'portfolio'})
            },

            # Data alerts
            {
                'type': 'data',
                'subtype': 'employment_updated',
                'severity': 'INFO',
                'message': 'Employment data updated - 150 records',
                'context': json.dumps({'records': 150})
            },
            {
                'type': 'data',
                'subtype': 'jobless_spike',
                'severity': 'WARNING',
                'message': 'Jobless claims spike detected: 12.5% above 4-week average',
                'context': json.dumps({'spike_percent': 12.5})
            },
            {
                'type': 'data',
                'subtype': 'data_stale',
                'severity': 'WARNING',
                'message': 'employment_data data is stale - 8 days old',
                'context': json.dumps({'type': 'employment_data', 'days_old': 8})
            },

            # System alerts
            {
                'type': 'system',
                'subtype': 'system_startup',
                'severity': 'INFO',
                'message': 'BigBrotherAnalytics system started',
                'context': json.dumps({})
            },
            {
                'type': 'system',
                'subtype': 'circuit_breaker_opened',
                'severity': 'CRITICAL',
                'message': 'Circuit breaker OPENED - Trading halted: Error rate exceeded threshold',
                'context': json.dumps({'reason': 'Error rate exceeded threshold'})
            },
            {
                'type': 'system',
                'subtype': 'schwab_api_error',
                'severity': 'ERROR',
                'message': 'Schwab API error (count: 3): Connection timeout',
                'context': json.dumps({'error': 'Connection timeout', 'count': 3})
            },

            # Performance alerts
            {
                'type': 'performance',
                'subtype': 'signal_generation_slow',
                'severity': 'WARNING',
                'message': 'Signal generation slow: 650.00ms (threshold: 500ms)',
                'context': json.dumps({'duration_ms': 650.0})
            },
            {
                'type': 'performance',
                'subtype': 'high_memory_usage',
                'severity': 'WARNING',
                'message': 'High memory usage: 85.0%',
                'context': json.dumps({'usage_percent': 85.0})
            },
            {
                'type': 'performance',
                'subtype': 'latency_spike',
                'severity': 'WARNING',
                'message': 'order_execution latency spike: 150.00ms (2.5x baseline)',
                'context': json.dumps({
                    'operation': 'order_execution',
                    'current_ms': 150.0,
                    'baseline_ms': 60.0,
                    'multiplier': 2.5
                })
            }
        ]

        count = 0
        for alert in sample_alerts:
            conn.execute(f"""
                INSERT INTO alerts (
                    alert_type, alert_subtype, severity, message, context, source, throttle_key
                ) VALUES (
                    '{alert['type']}',
                    '{alert['subtype']}',
                    '{alert['severity']}',
                    '{alert['message'].replace("'", "''")}',
                    '{alert['context']}',
                    'test_script',
                    '{alert['type']}:{alert['subtype']}:{alert['severity']}'
                )
            """)
            count += 1

        conn.commit()
        print(f"‚úÖ PASSED: Inserted {count} sample alerts")

        # Verify inserts
        result = conn.execute("SELECT COUNT(*) FROM alerts").fetchone()
        total_alerts = result[0]
        print(f"   Total alerts in database: {total_alerts}")

        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_alert_queries():
    """Test 3: Test alert queries and views."""
    print("\n" + "=" * 70)
    print("TEST 3: Alert Queries and Views")
    print("=" * 70)

    try:
        db_path = BASE_DIR / 'data' / 'bigbrother.duckdb'
        conn = duckdb.connect(str(db_path), read_only=True)

        # Test 1: Count alerts by severity
        print("\nAlerts by Severity:")
        results = conn.execute("""
            SELECT severity, COUNT(*) as count
            FROM alerts
            GROUP BY severity
            ORDER BY count DESC
        """).fetchall()

        for severity, count in results:
            print(f"  {severity}: {count}")

        # Test 2: Count alerts by type
        print("\nAlerts by Type:")
        results = conn.execute("""
            SELECT alert_type, COUNT(*) as count
            FROM alerts
            GROUP BY alert_type
            ORDER BY count DESC
        """).fetchall()

        for alert_type, count in results:
            print(f"  {alert_type}: {count}")

        # Test 3: Recent critical alerts
        print("\nRecent Critical Alerts:")
        results = conn.execute("""
            SELECT timestamp, message
            FROM alerts
            WHERE severity = 'CRITICAL'
            ORDER BY timestamp DESC
            LIMIT 5
        """).fetchall()

        if results:
            for ts, msg in results:
                print(f"  {ts}: {msg}")
        else:
            print("  (none)")

        # Test 4: Unsent alerts
        print("\nUnsent Alerts:")
        unsent_count = conn.execute("""
            SELECT COUNT(*)
            FROM alerts
            WHERE sent = false
        """).fetchone()[0]
        print(f"  Count: {unsent_count}")

        print("\n‚úÖ PASSED: All queries executed successfully")

        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå FAILED: {e}")
        return False


def test_alert_processor():
    """Test 4: Test alert processor in test mode."""
    print("\n" + "=" * 70)
    print("TEST 4: Alert Processor (Test Mode)")
    print("=" * 70)

    try:
        import subprocess

        # Run alert processor in test mode (3 iterations)
        print("Running alert processor in test mode...")
        print("(This will process alerts but not actually send emails/Slack)")

        result = subprocess.run(
            ["uv", "run", "python",
             str(BASE_DIR / "scripts" / "monitoring" / "alert_processor.py"),
             "--test"],
            cwd=str(BASE_DIR),
            capture_output=True,
            text=True,
            timeout=15  # 3 iterations * 5 seconds
        )

        # Check if it ran without errors
        if "Alert processor started" in result.stdout or "Alert processor started" in result.stderr:
            print("‚úÖ PASSED: Alert processor started successfully")
        else:
            print("‚ö†Ô∏è  WARNING: Could not verify alert processor startup")
            print("   This is expected if you interrupted it (Ctrl+C)")

        return True

    except subprocess.TimeoutExpired:
        print("‚úÖ PASSED: Alert processor ran for 15 seconds (expected)")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  WARNING: {e}")
        print("   (This test requires alert processor dependencies)")
        return True  # Don't fail test for this


def test_dashboard_integration():
    """Test 5: Verify dashboard can read alerts."""
    print("\n" + "=" * 70)
    print("TEST 5: Dashboard Integration")
    print("=" * 70)

    try:
        db_path = BASE_DIR / 'data' / 'bigbrother.duckdb'
        conn = duckdb.connect(str(db_path), read_only=True)

        # Simulate dashboard queries
        queries = [
            ("Total alerts", "SELECT COUNT(*) FROM alerts"),
            ("Unacknowledged alerts", """
                SELECT COUNT(*) FROM alerts
                WHERE acknowledged = false
                  AND severity IN ('ERROR', 'CRITICAL')
            """),
            ("Alerts today", """
                SELECT COUNT(*) FROM alerts
                WHERE DATE(timestamp) = CURRENT_DATE
            """),
            ("Recent alerts", """
                SELECT id, severity, alert_type, message
                FROM alerts
                ORDER BY timestamp DESC
                LIMIT 10
            """)
        ]

        all_passed = True
        for name, query in queries:
            try:
                result = conn.execute(query).fetchall()
                print(f"‚úÖ {name}: Success")
            except Exception as e:
                print(f"‚ùå {name}: Failed - {e}")
                all_passed = False

        if all_passed:
            print("\n‚úÖ PASSED: All dashboard queries work")
        else:
            print("\n‚ùå FAILED: Some dashboard queries failed")
            return False

        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå FAILED: {e}")
        return False


def main():
    """Run all tests."""
    print("\n" + "=" * 70)
    print("BigBrotherAnalytics Alert System Test Suite")
    print("=" * 70)
    print(f"Test started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    tests = [
        ("Database Schema", test_alert_database_schema),
        ("Insert Sample Alerts", test_insert_sample_alerts),
        ("Alert Queries", test_alert_queries),
        ("Alert Processor", test_alert_processor),
        ("Dashboard Integration", test_dashboard_integration)
    ]

    results = []

    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n‚ùå {test_name} crashed: {e}")
            results.append((test_name, False))

    # Summary
    print("\n" + "=" * 70)
    print("TEST SUMMARY")
    print("=" * 70)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for test_name, result in results:
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{status}: {test_name}")

    print("\n" + "=" * 70)
    print(f"Results: {passed}/{total} tests passed")
    print("=" * 70)

    if passed == total:
        print("\nüéâ All tests passed! Alert system is working correctly.")
        print("\nNext steps:")
        print("1. Configure email/Slack in configs/alert_config.yaml")
        print("2. Set environment variables (EMAIL_USERNAME, SLACK_WEBHOOK_URL, etc.)")
        print("3. Run alert processor: uv run python scripts/monitoring/alert_processor.py")
        print("4. View alerts in dashboard: Alerts tab")
        return 0
    else:
        print(f"\n‚ùå {total - passed} test(s) failed. Please review the errors above.")
        return 1


if __name__ == '__main__':
    sys.exit(main())
